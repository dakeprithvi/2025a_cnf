\documentclass[fontsize=11pt]{article}
\usepackage[margin=0.75in]{geometry}
\usepackage{color}
\usepackage{graphicx}
\usepackage{float}
\usepackage{polynom}
\usepackage{placeins}
\usepackage{longtable}
\usepackage{gensymb}
\usepackage{tikz}
\tikzset{every picture/.style={font=\normalsize}}
\DeclareOldFontCommand{\rm}{\normalfont\rmfamily}{\mathrm}
\DeclareOldFontCommand{\it}{\normalfont\rmfamily}{\mathrm}
\usepackage{mathtools}
\usepackage{hyperref}
\usepackage{pgfplots}
\hypersetup{colorlinks=false,
            pdfborder={0 0 0}}
\renewcommand{\thefootnote}{\alph{footnote}}
\newcommand{\R}{\mathbb{R}}
\usepackage{amsmath, bm}   % Extra math commands and environments from the AMS
\usepackage{amssymb}   % Special symbols from the AMS
\usepackage{amsthm}    % Enhanced theorem and proof environments from the AMS
\usepackage{latexsym}  % A few extra LaTeX symbols
\usepackage{rxn}
\usepackage[version=4]{mhchem}
\usepackage{algorithm, algpseudocode}
\usepackage{cleveref}
\usepackage{url}
\newcommand{\norm}[1]{\lVert #1 \rVert}
\providecommand{\email}{}
\renewcommand{\email}[1]{\texttt{#1}}
\usepackage{caption}
\captionsetup{labelfont=bf, labelsep=period, labelformat=simple, labelsep=colon, figurename=Fig.}
\usepackage[authoryear, round]{natbib}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{hypothesis}[theorem]{Hypothesis}
\newtheorem{property}[theorem]{Property}

%\newcommand{\tL}{\tilde{L}}

\graphicspath{{./}{./figures/}{./figures/paper/}}

\setcounter{topnumber}{2}              %% 2
\setcounter{bottomnumber}{1}           %% 1
\setcounter{totalnumber}{3}            %% 3
\renewcommand{\topfraction}{0.9}       %% 0.7
\renewcommand{\bottomfraction}{0.9}    %% 0.3
\renewcommand{\textfraction}{0.1}      %% 0.2
\renewcommand{\floatpagefraction}{.7}  %% 0.5

\title{\bf{Neural Ordinary Differential Equations}}
\author{Prithvi Dake\\
Department of Chemical Engineering, University of California, Santa Barbara}
\date{\textit{ME255NN: Neural Networks for modeling, optimization and control} \\
\textit{Winter 2025}}

\begin{document}

\maketitle
\section{Introduction}

Conventional neural network architectures, such as recurrent neural networks 
(RNNs) and residual networks (ResNets), can be viewed as discrete approximations
of ordinary differential equations (ODEs), specifically resembling the explicit
Euler scheme. Neural ODEs (NODEs) extend these architectures into a continuous 
framework, providing a more principled way of modeling dynamical systems.

One major challenge in training NODEs is gradient propagation during backpropagation.
Unlike traditional architectures, where intermediate states are stored for
gradient computation, NODEs require solving an augmented ODE system, involving
adjoint sensitivity equations, to compute gradients efficiently. This adjoint sensitivity 
method significantly reduces memory requirements compared to brute-force 
backpropagation \& forward sensitivity equations. Overcoming this training limitation enables NODEs to be 
applied in broader contexts, such as continuous normalizing flows and state-space 
models.

In this review, we cover fundamental concepts and recent advancements in NODEs. 
We begin with a discussion on artificial neural networks (ANNs) implemented in 
a physics-informed manner that does not involve recurrence or differential 
modeling as shown by \cite{raissi:perdikaris:karniadakis:2019}. Next, we explore
discrete data-driven models for process systems using ResNets and RNNs. 
Building on these foundations, we introduce sensitivity and adjoint equation 
methods referring \cite{stapor:froehlich:hasenauer:2018}, and then introduce the 
formal development of NODEs by \cite{chen:rubanova:bettencourt:duvenaud:2018}. 

We then review advanced applications, including generative latent models by
\cite{rubanova:chen:duvenaud:2019}, continuous normalizing flows by
\cite{grathwohl:chen:bettencourt:sutskever:duvenaud:2018}, and robustness 
analyses of NODEs by \cite{yan:du:tan:feng:2019}. Finally, we discuss efficient 
NODE training techniques compiled in \cite{finlay:jacobsen:nurbekyan:oberman:2020}.

The structure of this report is as follows: We first introduce conventional 
neural network architectures, such as RNNs and ResNets, and their connection 
to NODEs. Next, we explain how backpropagation is handled in NODEs and discuss 
applications in continuous normalizing flows and NODE-based state-space models. 
Most of the sections give exemplar implementations. 
The report concludes with a summary of key findings and an overview of ongoing 
developments in the field.

\section{Background}

\subsection{ANNs for Physics-Informed Learning}

In most engineering systems, we only have access to noisy measurements of 
input-output data, typically originating from high-dimensional, nonlinear dynamic 
systems. While such systems can be approximated using finite impulse response (FIR) 
or autoregressive exogenous (ARX) models \citep{ljung:1999}, these approaches often fail to respect 
fundamental physical laws. One way to address this limitation is by penalizing 
violations of these laws—a key idea behind physics-informed neural networks (PINNs), 
as introduced by \cite{raissi:perdikaris:karniadakis:2019}.

However, it is important to view PINNs not merely as data-driven models but 
rather as a solution strategy for PDEs and ODEs. Fundamentally, they operate 
as \textit{methods of weighted residuals} \citep{villadsen:stewart:1967}—specifically, collocation schemes—where 
the residual is minimized at selected collocation points. While PINNs can be 
used to learn certain model parameters, their results can be difficult to interpret 
without a fundamental understanding of the underlying physics.

Recent research has leveraged the PINN framework to enforce simple mass and energy 
balance equations at steady-state, as this is often the only available information 
in practical scenarios. \Cref{alg:PINNs} outlines the basic algorithm for training 
a PINN applied to an ODE system.

\begin{algorithm}[h]
\caption{Training a Physics-Informed Neural Networks (PINNs)}
\label{alg:PINNs}
\begin{algorithmic}[1]
\State \textbf{Input:} Neural network architecture $f_{NN}$
\State \textbf{Physical Model:} $Lx=f \quad B_1 x = 0 \quad B_2 x = 0$
\Comment{True or known physics}
\State \textbf{Initialize} neural network parameters $\theta$
\Repeat
    \State $x = f_{NN}(x,t; \theta)$
    \State $V_{ODE} = \norm{Lx - f}^{2}$ 
    \Comment{Prediction error minimization} 
    \State $V_{BC} = \norm{B_1 x}^{2} + \norm{B_2 x}^{2}$
    \Comment{Enforce boundary conditions}
    \State $V = \lambda_1 V_{PDE}  + \lambda_2 V_{BC}$
    \Comment{Combine loss terms}
    \State $\theta \leftarrow \theta - \eta \nabla_{\theta} V$
    \Comment{Update $\theta$ using gradient descent}
\Until{convergence criteria is met}
\State \textbf{Return} trained model $f_{NN}$
\end{algorithmic}
\end{algorithm}
    
\subsection{ResNets and RNNs for Process Systems}

Most engineering systems operating near a steady state can be effectively modeled 
using discrete linear time-invariant (DLTI) systems. These state-space models are 
particularly well-suited for systems experiencing small perturbations.
For highly nonlinear systems, ResNets and RNNs offer a similar state-space modeling 
approach. In the system identification community, ResNet and RNN models are commonly 
employed for this purpose, as illustrated in \cref{eq:resrnn} on left and right respectively.

\begin{align}
    x^+ &= x + f_{NN} (x, u; \theta) &\qquad x^+ = f_{NN} (x, u; \theta)\notag \\ 
    y &= g_{NN} (x, u; \theta) &\qquad y = g_{NN} (x, u; \theta)
    \label{eq:resrnn}
\end{align}

There are two approaches to learning the parameters $\theta$ in \cref{eq:resrnn}: 
\textit{multi-step prediction error minimization} and \textit{single-step prediction 
error minimization}. 
The single-step approach minimizes the prediction error at each time step independently, 
while the multi-step approach considers the accumulated error over multiple time steps. 
In practice, the multi-step method tends to be more stable, especially in the presence 
of noisy measurements.

Consider following \textit{true} model of linear chemical kinetics taking place
in a well-mixed batch reactor with $c = (c_A, c_B, c_C)^T$ and initial concentration
$c_0$:
\begin{rxn*}{} 
A \rlh[k_1][k_{-1}] 2 B, \qquad  B \rarrow[k_2] C
\label{rxn:atobtoc}
\end{rxn*}
\begin{gather}
\begin{bmatrix} \dot{c}_A \\ \dot{c}_B \\ \dot{c}_C \end{bmatrix}
=\begin{bmatrix}
    -k_{1} & k_{-1} & 0 \\
    2k_{1} & 2k_{-1} - k_2 & 0 \\
    0 & k_{2} & 0
\end{bmatrix}
\begin{bmatrix}  c_A \\ c_B \\ c_C \end{bmatrix} 
\label{eq:atobtoc}
\end{gather}
Assume we have full-state measurement i.e.we measure all the three concentrations. Thus, 
a ResNet model can be easily trained to predict the concentration profile over 
time as shown in \cref{fig:resnet}. A similar example can be reproduced using an 
RNN model. Note we used multi-step prediction error minimization. One disadvantage 
of such iterative models is that they require large memory
to store intermediate states for gradient propagation (since we basically
apply chain-rule while differentiating through the solution). Another disadvantage is they 
are discrete in nature and thus, can struggle when the data is not sampled at regular intervals.

\begin{figure}
    \centering
    \includegraphics[width=0.55\textwidth, page=2]{ABC_plot.pdf} 
    \caption{Concentration profiles of species A, B, and C in a batch reactor. The 
    discrete ResNet model does quite a good job to predict the concentration profiles.}
    \label{fig:resnet}
\end{figure}

\subsection{Forward and backward sensitivity/adjoint methods}
\label{sec:sens}
\subsubsection{Forward Sensitivity}


Here we give a quick overview of both the forward and backward sensitivity/adjoint 
equations for ODEs. Consider following non-linear state-space model:
\begin{align}
    \dot{x} &= f(x, u; \theta) \qquad x(0) = g(x_0; \theta)\notag 
    \label{eq:ssode}
\end{align}
We assume full state measurement (i.e. $y=x$). Consider a least-squares objective
to measure the fit to the data ($\tilde{x}$):
\begin{align}
    \min\limits_{\theta} V(x) = \norm{\tilde{x} - x}^2 
\end{align}
We refer \cite{rawlings:ekerdt:2020} for following derivation. To propagate the gradient we need to solve the sensitivity equations:
\begin{align}
    \dfrac{\partial V}{\partial \theta^T} &= -2 (\tilde{x} - x)^T \dfrac{\partial x}{\partial \theta^T} \notag \\ 
    S &= \dfrac{\partial x}{\partial \theta^T}
    \label{eq:sens}
\end{align}
where $S$ is the \textit{sensitivity} matrix of the model solutions with parameters. We differentiate $S$ to obtain:
\begin{align}
    \dfrac{d S}{dt} &= \dfrac{d}{dt} \left(\dfrac{\partial x}{\partial \theta^T}\right) =
    \dfrac{\partial}{\partial\theta^T} \left(\dfrac{d x}{dt}\right) = 
    \dfrac{\partial }{\partial \theta^T} f
\end{align}
Using chain rule on $f$, we get following matrix equation:
\begin{align}
    \dfrac{dS}{dt} = \dfrac{\partial f}{\partial x^T}S + \dfrac{\partial f}{\partial \theta^T} \qquad  S(0) = \dfrac{\partial g}{\partial \theta^T}
\end{align}
Thus, we can construct following augmented ODE system:
\begin{align}
    \begin{bmatrix} \dot{x} \\ \dot{S} \end{bmatrix} = 
    \begin{bmatrix} f \\ \dfrac{\partial f}{\partial x^T}S + \dfrac{\partial f}{\partial \theta^T} \end{bmatrix}
    \qquad
    \begin{bmatrix} x(0) \\ S(0) \end{bmatrix} =
    \begin{bmatrix} x_0 \\ \dfrac{\partial g}{\partial \theta^T} \end{bmatrix}
    \label{eq:augsensode}
\end{align}
This augmented system can be solved using any ODE solver, allowing gradient 
propagation. However, if $\theta \in \R^{p}$ and $x \in \R^{n}$, we need to 
solve $S \in \R^{n+p}$ equations i.e. the cost increases with $p$. Thus, forward
sensitivity is not an efficient method to propagate gradients. However, we can circumvent
the problem of linear increase in sensitivity equations using backward adjoint equations. This key advantage 
of backward adjoint method contributed to the feasibility of Neural ODEs (NODEs), beyond their interpretation 
as a continuous counterpart to Euler-step based architectures like ResNets. We next show 
a short example on solving the augmented ODE system for forward sensitivity. Consider, 
following kinetics:
\begin{align}
    \dot{c}_A &= -kc_A \notag \\
    c_A(0) &= c_{A0}
\end{align}
Say we want to calculate sensitivities wrt $k$ and $c_{A0}$. With reference to \cref{eq:augsensode},
for $S_1 = \dfrac{\partial c_A}{\partial k}$ and $S_2 = \dfrac{\partial c_A}{\partial c_{A0}}$,
we have following augmented system:
\begin{align}
    \begin{bmatrix} 
        \dot{c}_A \\
        \dot{S_1} \\ 
        \dot{S_2} 
    \end{bmatrix} = 
    \begin{bmatrix}
        -kc_A \\
        -kS_1 - c_A \\
        -kS_2 \end{bmatrix}
    \qquad
    \begin{bmatrix} 
        c_A(0) \\ 
        S_1(0) \\ 
        S_2(0) 
    \end{bmatrix} =
    \begin{bmatrix} 
        c_{A0} \\ 
        0 \\ 
        1
    \end{bmatrix}
\end{align}
If we were learning the parameter $k$ and initial condition $c_{A0}$, we could
show a gradient descent update as follows:
\begin{align}
    \begin{bmatrix} k \\ c_{A0} \end{bmatrix} \leftarrow
    \begin{bmatrix} k \\ c_{A0} \end{bmatrix}
    - \eta 
    \begin{bmatrix} 
        -2 (\hat{c}_A  - c_A)^T S_1 \\ 
        -2 (\hat{c}_A  - c_A)^T S_2
    \end{bmatrix}
\end{align}

\subsubsection{Backward Sensitivity}

In this section we redefine the objective function as an integral over time.
The integral formulation allows us to derive the adjoint equation. We refer \cite{sengupta:friston:penny:2014} 
that gives a straightforward proof of the adjoint equation than the one in
\cite{chen:rubanova:bettencourt:duvenaud:2018}.
Consider following least-squares objective for \cref{eq:ssode} and the Lagrange functional:

\begin{align}
    \min\limits_{\theta}V(x) &= \int_0^t \norm{x - \hat{x}}^2 dt = \int_0^t g(x)dt \notag \\
    \min\limits_{\theta, \lambda}\mathcal{L} &= \int_0^t g dt + \int_0^t \lambda(t)^T \left(f - \dfrac{dx}{dt}\right) dt
\end{align}
Hence,
\begin{align}
    \dfrac{\partial \mathcal{L}}{\partial \theta^T} &= \int_0^t \dfrac{\partial g}{\partial x^T} \dfrac{\partial x}{\partial \theta^T} dt + 
    \int_0^t \lambda^T \left(\dfrac{\partial f}{\partial x^T} \dfrac{\partial x}{\partial \theta^T} + \dfrac{\partial f}{\partial \theta^T} - \dfrac{\partial}{\partial \theta^T}\dfrac{dx}{dt}\right) dt \notag \\
    \dfrac{\partial \mathcal{L}}{\partial \theta^T} &= \int_0^t \dfrac{\partial g}{\partial x^T} \dfrac{\partial x}{\partial \theta^T} dt + 
    \int_0^t \lambda^T \left(\dfrac{\partial f}{\partial x^T} \dfrac{\partial x}{\partial \theta^T} + \dfrac{\partial f}{\partial \theta^T} - \dfrac{d}{dt}\dfrac{\partial x}{\partial \theta^T}\right) dt \notag \\
    \dfrac{\partial \mathcal{L}}{\partial \theta^T} &= \int_0^t \lambda^T \dfrac{\partial f}{\partial \theta^T} dt + \int_0^t \left(\dfrac{\partial g}{\partial x^T}
    + \lambda^T \dfrac{\partial f}{\partial x^T} - \lambda^T\dfrac{d}{dt}\right)\dfrac{\partial x}{\partial \theta^T} dt
\end{align}
The term $\int_0^t{\lambda^T \dfrac{d}{dt} \dfrac{\partial x}{\partial \theta^T}dt}$ 
can be solved using integration by parts. Thus, we have:

\begin{align}
    \dfrac{\partial \mathcal{L}}{\partial \theta^T} &= \int_0^t \lambda^T \dfrac{\partial f}{\partial \theta^T} dt + \int_0^t \left(\dfrac{\partial g}{\partial x^T}
    + \lambda^T \dfrac{\partial f}{\partial x^T} + \dfrac{d\lambda^T}{dt}\right)\dfrac{\partial x}{\partial \theta^T} dt + \lambda^T(0)\dfrac{\partial x}{\partial \theta^T}|_0
    - \lambda^T(T)\dfrac{\partial x}{\partial \theta^T}|_t
    \label{eq:adjoint}
\end{align}

Now, the whole objective of backward sensitivity is to avoid calculating $\dfrac{\partial x}{\partial \theta^T}$.
Also note that the equality constraint in the Langrange functional is always satisfied
since we \textit{solve} the ODE system. Thus we get to choose $\lambda$ such that the terms
associated with $\dfrac{\partial x}{\partial \theta^T}$ vanish. Also, we can 
easily calculate $\dfrac{\partial x}{\partial \theta^T}|_0$ but we would like to set
$\dfrac{\partial x}{\partial \theta^T}|_t = 0$. Thus, we can construct following adjoint 
equations:

\begin{align}
    \dfrac{d\lambda^T}{dt} &= -\dfrac{\partial g}{\partial x^T} - \lambda^T \dfrac{\partial f}{\partial x^T} \notag \\
    \lambda(T) &= 0
\end{align}
Referring to \cref{eq:adjoint}, we see $\dfrac{\partial V}{\partial \theta^T} = 
\dfrac{\partial \mathcal{L}}{\partial \theta^T}$.
\cite{chen:rubanova:bettencourt:duvenaud:2018} uses objective function of the form:
\begin{align}
    \min\limits_{\theta}V(x) = \int_0^t \norm{x - \hat{x}}^2 \delta(t) dt
\end{align}
Hence, the adjoint equations for their case are:
\begin{align}
    \dfrac{d\lambda^T}{dt} &= -\lambda^T \dfrac{\partial f}{\partial x^T} \notag \\
    \lambda(t)^T &= - \dfrac{\partial g}{\partial x^T}|_t = -\dfrac{\partial V}{\partial x^T}|_t \notag \\
    \dfrac{\partial V}{\partial \theta^T} &= \lambda^T(0)\dfrac{\partial x}{\partial \theta^T}|_0 + \int_0^t   \lambda^T \dfrac{\partial f}{\partial \theta^T} dt
    \label{eq:adjointnode}
\end{align}
Hence, $\lambda = \dfrac{\partial V}{\partial x}$ as we see from the terminal 
condition in \cref{eq:adjointnode}.
Thus, we need to solve the augmented ODE system once forward 
and once backward in each optimal iteration. We need a forward pass to store
the value of $\dfrac{\partial g}{\partial x^T}|_t$ and $x_t$. Also, note that the number 
of adjoint equations do not increase with parameters (i.e $\lambda \in \R^n$ unlike $S \in \R^{n \times p+1}$). 
We can evaluate the gradient in one go as shown in \cref{eq:adjointnode}. 
However, such method is not 
an ultimate panacea. Such systems are still vulnerable to the problems commonly faced by
numerical ODE solvers like stiffness, accuracy, etc. One can analyze the stiffness
of the adjoint ODE by simply inspecting the eignevalues of the Jacobian matrix $\dfrac{\partial f}{\partial x^T}$
at different time points. Sometimes we may end up with noisy gradients which may lead to poor convergence.
Some recent remedies is solving adjoint equation in multiple time-intervals rather than 
a single long time-interval
and storing intermediate points, often called as \textit{checkpointing}.
 \citep{zhuang:dvornek:li:tatikonda:papademetris:duncan:2020}. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth, page=4]{ABC_plot.pdf} 
    \caption{Consider $\dot{\lambda} = -e \lambda$ for $e = \pm 10$. 
    We see that the adjoint variable will either explode or vanish.
    Thus $\dfrac{\partial V}{\partial \theta} = \lambda(0) = 10^{\pm 5}$. 
    A simple example to show how an ill-conditioned
    adjoint system can lead to poor convergence.}
    \label{fig:node}
\end{figure}

\subsection{Neural Ordinary Differential Equations}

With the background established in \cref{sec:sens}, we can now introduce the algorithm
for training NODEs. The key idea is to replace the right-hand side of the ODE system
with a neural network. With auto-differentiation we can easily construct the augmented
ODE system and solve it using any ODE solver. 

\begin{algorithm}[h]
\caption{Training a Neural Ordinary Differential Equation (NODE)}
\label{alg:NODE}
\begin{algorithmic}[1]
\State \textbf{Input:} Neural network architecture $f_{NN}$
\State \textbf{ODE:} 
$
    \begin{bmatrix} \dot{x} \\ \dot{\lambda^T} \end{bmatrix} = 
    \begin{bmatrix} f_{NN} \\ -\lambda^T \dfrac{\partial f_{NN}}{\partial x^T}\end{bmatrix}
    \qquad
    \begin{bmatrix} x(t) \\ \lambda(t) \end{bmatrix} =
    \begin{bmatrix} x_t \\ - \dfrac{\partial g}{\partial x^T}|_{t} \end{bmatrix}
    \label{eq:augsens}
$
\Comment{Construct the augmented ODE using \texttt{PyTorch}}
\State \textbf{Initialize} neural network parameters $\theta$
\Repeat
    \State $V = \norm{\hat{x} - x}^2$
    \Comment{Forward solve to get the loss $V$}
    \State $\hat{x}_{aug} = \text{ODESolve}(f_{aug}, x_{aug}(0), T, t_0)$
    \State $\dfrac{\partial V}{\partial \theta^T} = \lambda^T(0)\dfrac{\partial x}{\partial \theta^T}|_0 + \int_0^t   \lambda^T \dfrac{\partial f}{\partial \theta^T} dt$
    \Comment{Construct the gradient wrt loss}
    \State $\theta \leftarrow \theta - \eta \nabla_{\theta} V$
\Until{convergence criteria is met}
\State \textbf{Return} trained model $f_{NN}$
\end{algorithmic}
\end{algorithm}
We close the section with the same example as shown in \cref{eq:atobtoc} but now
we use a NODE to predict the concentration profiles. The results are shown in
\cref{fig:node}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth, page=1]{ABC_plot.pdf} 
    \caption{Concentration profiles of species A, B, and C in a batch reactor. The
    NODE model also does quite a good job to predict the concentration profiles. 
    In fact for such simple problem, we hardly see any difference between ResNet and NODE.}
    \label{fig:node}
\end{figure}

\subsection{Generative latent models based on continuous normalizing flows}

The NODE paper applies the same motivation to develop continuous normalizing flows
\citep{grathwohl:chen:bettencourt:sutskever:duvenaud:2018}.
Interested reader can refer the paper for proof of theorem on instantaneous change of variables
\citep{chen:rubanova:bettencourt:duvenaud:2018}.
The key idea is the neural ODE rhs is trained to conserve the probability density 
while maximizing log-likelihood to describe the data. The framework can be described 
as follows:
\begin{align}
    \begin{bmatrix}
        x_0 \\
        \log p(x) - \log p(x_0)
    \end{bmatrix}
    =
    \int_{t}^{0}
    \begin{bmatrix}
        f_{NN}(x, u; \theta) \\
        -\mathrm{Tr} \left(\dfrac{\partial f_{NN}}{\partial x^T}\right)
    \end{bmatrix} dt;
    \qquad
    \begin{bmatrix}
        x(t) \\
        \log p(x) - \log p(x_t)
    \end{bmatrix}   
    =
    \begin{bmatrix}
        x_t \\
        0
    \end{bmatrix}
\end{align}
We assume, $x_0 \sim \mathcal{N}(0, \sigma^2I)$ and thus the objective function is:
\begin{align}
    \min\limits_{\theta} V(x) = -\log p(x)
\end{align}
That's a powerful framework to model distributions (say a human face composed of pixels).
However, we are more interested in using similar generative framework for chemical kinetics. 
Thus, we again use the same example as shown in \cref{eq:atobtoc} but we also model 
how the uncertainty in the initial conditions decreases as we add more measurement points.
The results are shown in \cref{fig:cnf}. The system we solve is:

\begin{align}
    \begin{bmatrix} \dot{c}_A \\ \dot{c}_B \\ \dot{c}_C \\ \dot{\log p} \end{bmatrix}
    = \begin{bmatrix}
        -k_{1}c_A + k_{-1}c_B  \\
        2k_{1}c_A +  2k_{-1}c_B - k_2c_B \\
        k_{2}c_B\\
        -\mathrm{Tr} \left(\dfrac{\partial f_{NN}}{\partial x^T}\right)
    \end{bmatrix};
    &\qquad
    \begin{bmatrix} c_A(0) \\ c_B(0) \\ c_C(0) \\ \log p(0) \end{bmatrix} =
    \begin{bmatrix} 1 \\ 0 \\ 0 \\ \log{\mathcal{N}([c_A, c_B, c_C]^T, \sigma^2I)} \end{bmatrix} \notag \\
    \min\limits_{\theta} V(x) &= -\log p(x) + \norm{c - \tilde{c}}^2
\end{align}
The author would like to draw parallels to the classical Kalman filter \citep{kalman:1960} that also does the similar job,
but the continuous normalizing flow can be applied to any non-linear dynamical system.
\begin{figure}[h]
    \centering
    \includegraphics[width=1\textwidth, page=3]{ABC_plot.pdf} 
    \caption{Results for chemical kinetics modeled as continuous normalizing
    flow. We start with a high uncertainty in the initial conditions. The spread in 
    probability decreases as we add more measurement points. Readers would like
    to draw similarities to Kalman filter, only in this case we can apply it to 
    any non-linear continuous dynamical system.}
    \label{fig:cnf}
\end{figure}

\subsection{Robustness analysis of NODEs}

Well-posedness of an IVP is given by following theorem \citep{ascher:petzold:1998}:
\begin{theorem}
    Let $f(t,x)$ be continuous for all $(t,x)$ in a region $\mathcal{D} = {0 \leq t \leq b, |x| \leq \infty}$. 
    Moreover assume Lipschitz contnuity in $x$, then there exists a constant $L$ such that:
    \begin{align*}
        \norm{f(t,x) - f(t,\bar{x})} \leq L \norm{x-\bar{x}}
    \end{align*}   
\end{theorem}
Thus, for ODEs with slightly perturbed initial conditions, the solution should not
intersect though they can approach the same trajectory. Thus, the solution of an 
ODE can be sandwhiched between two other perturbed solutions. Refer to \cref{fig:robust} for
a simple example that again follows the kinetics in \cref{eq:atobtoc}.
\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth, page=5]{ABC_plot.pdf} 
    \caption{Robustness analysis of ODEs. We see that the solution $c_{B2}$ 
    is sandwiched between two perturbed solutions $c_{B1}, c_{B3}$, 
    though all approach the same steady-state. Also note that the slightly time-shifted
    solution appears as a perturbed solution}
    \label{fig:robust}
\end{figure}
Thus, following above idea, \cite{yan:du:tan:feng:2019} developed robust NODEs.
The idea is the perturbed solution can be seen as time-shifted solution of the
original ODE sytem. Using uniqueness of solutions, time-invariant NODEs can be regularized by
adding a penalty term to the loss function. The penalty term is given by:
\begin{align*}
    \norm{x(t+T)-x(t)} \leq \norm{\int_t^{t+T} f_{NN}(x, u; \theta) dt}
\end{align*} 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.55\textwidth, page=6]{ABC_plot.pdf} 
    \caption{If we train based only on prediction loss, the model can overfit.
    However, if we penalize the jacobian of the loss, we can regularize the model
    to damp the oscillations.}
    \label{fig:jacobnode}
\end{figure}

\cite{finlay:jacobsen:nurbekyan:oberman:2020} recommend to penalize the Jacobian of ODE rhs function
$(\nabla_x f)$ to damp oscillations that happen due to overfitting in neural ODE. A simple example
using polynomial fit is show in \cref{fig:jacobnode}.
\section{Conclusions}
In this review, we explored the mathematical foundations and practical applications 
of Neural Ordinary Differential Equations (NODEs), highlighting their connection 
to classical ODE-based modeling and modern machine learning approaches. We first 
established how NODEs extend traditional discrete architectures such as ResNets 
and RNNs by formulating neural networks as continuous dynamical systems. This 
formulation provides a more principled way to model physical and process-driven 
data while reducing memory constraints through adjoint-based sensitivity analysis.

A key focus of this review was the gradient computation techniques for NODEs. We 
discussed the forward sensitivity method, which requires solving an augmented ODE 
system but suffers from an increase in computational cost with the number of parameters. 
The adjoint sensitivity method, in contrast, offers a more efficient alternative by 
solving a backward ODE, making NODEs feasible for large-scale learning problems. While 
adjoint methods significantly improve efficiency, they are not free from challenges, 
as stiffness and numerical instabilities can still affect convergence.

We also explored continuous normalizing flows (CNFs), where NODEs are utilized to 
construct generative models that explicitly model probability density evolution. 
The application of CNFs to chemical kinetics demonstrated how this framework can 
be extended to physical modeling while drawing conceptual parallels with classical 
filtering techniques such as the Kalman filter. These methods provide powerful tools 
for uncertainty quantification and data-driven discovery in dynamical systems.

A critical aspect of NODE-based learning is the robustness of solutions. We examined 
how NODEs, as solutions to differential equations, inherit the stability properties 
of the underlying ODEs. In particular, well-posedness ensures that small perturbations 
in initial conditions do not lead to solution intersections, reinforcing the interpretability 
and reliability of NODE-based models. This insight was leveraged to propose robust NODEs, 
where regularization techniques enforce time-invariance by penalizing deviations between time-shifted trajectories.

Overall, NODEs present a compelling framework for modeling dynamical systems in a continuous, 
memory-efficient, and theoretically grounded manner. 

\section{Data availability and Code}
All the figures in the review have been generated by the author. The code for the
figures can be found at  

\newpage
\FloatBarrier
\bibliographystyle{abbrvnat}
\bibliography{cnf_bib, abbreviations,articles,books,unpub,proceedings}
\end{document}
